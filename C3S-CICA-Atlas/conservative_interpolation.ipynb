{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import sys\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lib.utils import latest_version, fix_360_longitudes\n",
    "from lib.interpolater import Interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverseDir(root, end):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(root):\n",
    "        for file in filenames:\n",
    "            if file.endswith((end)):\n",
    "                yield os.path.join(dirpath, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_domain(ds, lats_ref, lons_ref):\n",
    "    lons_d = ds.lon.data\n",
    "    lats_d = ds.lat.data\n",
    "    if (lons_d>180).any():\n",
    "        lons_d[lons_d>180] = lons_d[lons_d>180] -360\n",
    "    lons_d_max = np.max(lons_d)\n",
    "    lons_d_min = np.min(lons_d)\n",
    "    lats_d_max = np.max(lats_d)\n",
    "    lats_d_min = np.min(lats_d)\n",
    "\n",
    "    lons_ref_cut = lons_ref[(lons_ref>lons_d_min) & (lons_ref<lons_d_max)]\n",
    "    lats_ref_cut = lats_ref[(lats_ref>lats_d_min) & (lats_ref<lats_d_max)]\n",
    "\n",
    "    return lats_ref_cut, lons_ref_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load reference grid\n",
    "import xarray as xr\n",
    "\n",
    "# Especifica el archivo correcto dentro del directorio\n",
    "ruta_nc = \"/lustre/gmeteo/WORK/DATA/C3S-CDS/C3S-CICA-Atlas/v2/CORDEX-CORE/historical/t_CORDEX-CORE_historical_mon_197001-200512_v02.nc\"\n",
    "\n",
    "# Abre el archivo NetCDF\n",
    "ds_ref_025 = xr.open_dataset(ruta_nc, engine=\"netcdf4\")\n",
    "\n",
    "# Muestra informaciÃ³n del dataset\n",
    "print(ds_ref_025)\n",
    "root = '/lustre/gmeteo/WORK/DATA/C3S-CDS/C3S-CICA-Atlas/v2/CORDEX-EUR-11/historical/'\n",
    "ds_ref_012 = xr.open_dataset(f\"{root}t_CORDEX-EUR-11_historical_mon_197001-200512_v02.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files to interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### tasmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_esgf_local = '/lustre/gmeteo/DATA/ESGF/REPLICA/DATA/cordex/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_CORDEX = np.sort(list(traverseDir(root_esgf_local, '.nc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.DataFrame(index = np.arange(len(files_CORDEX)))\n",
    "da['files'] = files_CORDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "da.to_csv('files_CORDEX_lustre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/tasmin/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.sort(list(traverseDir(root, '.nc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "864/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conservative and Nearest interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### tasmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "int_attr = {'interpolation_method' : None, \n",
    "            'lats' : None,\n",
    "            'lons' : None,\n",
    "            'var_name' : 'tasmin'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in tqdm.tqdm(files):\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    if file.split('/')[-1].split('_')[1].split('-')[1] == '11':\n",
    "        lats_ref = np.sort(ds_ref_012.lat.data)\n",
    "        lons_ref = np.sort(ds_ref_012.lon.data)\n",
    "    elif file.split('/')[-1].split('_')[1].split('-')[1] == '22':\n",
    "        lats_ref = np.sort(ds_ref_025.lat.data)\n",
    "        lons_ref = np.sort(ds_ref_025.lon.data)\n",
    "         \n",
    "    filepath_root = '/'.join(file.split('/')[:-1])\n",
    "    filename_root = file.split('/')[-1]\n",
    "        \n",
    "    # open file\n",
    "    ds = xr.open_dataset(file)\n",
    "    # cut destination grid and update attr\n",
    "    lats_ref, lons_ref = select_domain(ds, lats_ref, lons_ref)\n",
    "    int_attr['lats'] = lats_ref\n",
    "    int_attr['lons'] = lons_ref\n",
    "    \n",
    "    # Conservative\n",
    "    int_attr['interpolation_method'] = 'conservative_normed'\n",
    "    filepath_dest = filepath_root.replace('/tasmin/', '/tasmin_C/')\n",
    "    filename_dest = file.split('/')[-1]\n",
    "    # check if the file aready exist\n",
    "    if os.path.isfile(file.replace('/tasmin/', '/tasmin_C/')):\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        # Interpolate\n",
    "        INTER = Interpolator(int_attr)\n",
    "        ds_inter = INTER(ds)\n",
    "        # save the results\n",
    "        if not os.path.exists(filepath_dest):\n",
    "            os.makedirs(filepath_dest)\n",
    "        mask = np.isnan(ds_inter['tasmin'])\n",
    "        ds_inter.to_netcdf(filepath_dest + '/' +  filename_dest)\n",
    "    \n",
    "        # NN\n",
    "        int_attr['interpolation_method'] = 'nearest_s2d'\n",
    "        filepath_dest = filepath_root.replace('/tasmin/', '/tasmin_N/')\n",
    "        filename_dest = file.split('/')[-1]\n",
    "        # Interpolate\n",
    "        INTER = Interpolator(int_attr)\n",
    "        ds_inter = INTER(ds)\n",
    "        # save the results\n",
    "        if not os.path.exists(filepath_dest):\n",
    "            os.makedirs(filepath_dest) \n",
    "        ds_inter['tasmin'] = ds_inter['tasmin'].where(~mask)\n",
    "        ds_inter.to_netcdf(filepath_dest + '/' +  filename_dest)\n",
    "        \n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### tasmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/tasmin/data-esgf-local/tasmax/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.sort(list(traverseDir(root, '.nc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "int_attr = {'interpolation_method' : None, \n",
    "            'lats' : None,\n",
    "            'lons' : None,\n",
    "            'var_name' : 'tasmax'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in tqdm.tqdm(files):\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    if file.split('/')[-1].split('_')[1].split('-')[1] == '11':\n",
    "        lats_ref = np.sort(ds_ref_012.lat.data)\n",
    "        lons_ref = np.sort(ds_ref_012.lon.data)\n",
    "    elif file.split('/')[-1].split('_')[1].split('-')[1] == '22':\n",
    "        lats_ref = np.sort(ds_ref_025.lat.data)\n",
    "        lons_ref = np.sort(ds_ref_025.lon.data)\n",
    "         \n",
    "    filepath_root = '/'.join(file.split('/')[:-1])\n",
    "    filename_root = file.split('/')[-1]\n",
    "        \n",
    "    # open file\n",
    "    ds = xr.open_dataset(file)\n",
    "    # cut destination grid and update attr\n",
    "    lats_ref, lons_ref = select_domain(ds, lats_ref, lons_ref)\n",
    "    int_attr['lats'] = lats_ref\n",
    "    int_attr['lons'] = lons_ref\n",
    "    \n",
    "    # Conservative\n",
    "    int_attr['interpolation_method'] = 'conservative_normed'\n",
    "    filepath_dest = '/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/tasmax_C/'\n",
    "    filename_dest = file.split('/')[-1]\n",
    "    # check if the file aready exist\n",
    "    if os.path.isfile(filepath_dest + filename_dest):\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        # Interpolate\n",
    "        INTER = Interpolator(int_attr)\n",
    "        ds_inter = INTER(ds)\n",
    "        # save the results\n",
    "        if not os.path.exists(filepath_dest):\n",
    "            os.makedirs(filepath_dest)\n",
    "        mask = np.isnan(ds_inter['tasmax'])\n",
    "        ds_inter.to_netcdf(filepath_dest +  filename_dest)\n",
    "    \n",
    "        # NN\n",
    "        int_attr['interpolation_method'] = 'nearest_s2d'\n",
    "        filepath_dest = '/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/tasmax_N/'\n",
    "        filename_dest = file.split('/')[-1]\n",
    "        # Interpolate\n",
    "        INTER = Interpolator(int_attr)\n",
    "        ds_inter = INTER(ds)\n",
    "        # save the results\n",
    "        if not os.path.exists(filepath_dest):\n",
    "            os.makedirs(filepath_dest) \n",
    "        ds_inter['tasmax'] = ds_inter['tasmax'].where(~mask)\n",
    "        ds_inter.to_netcdf(filepath_dest +  filename_dest)\n",
    "        \n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "int_attr = {'interpolation_method' : None, \n",
    "            'lats' : None,\n",
    "            'lons' : None,\n",
    "            'var_name' : None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_str = {'land-sea-mask': 'sftlf',\n",
    "             'orography': 'orog',\n",
    "             'urbanfraction': 'sftimf',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_str = {'land-sea-mask': 'sftlf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Dictionary of variable names\n",
    "vars_str = {\n",
    "    'land-sea-mask': 'sftlf',\n",
    "    'orography': 'orog',\n",
    "    'urbanfraction': 'sftimf',\n",
    "}\n",
    "\n",
    "# Iterate over models and variables\n",
    "for model in [\"RegCM\", \"REMO\"]:\n",
    "    for var_str, var_name in vars_str.items():\n",
    "        root = f\"/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/{model}/{var_str}/\"\n",
    "        print(root)\n",
    "        \n",
    "        files = np.sort(list(traverseDir(root, '.nc')))\n",
    "        print(files)\n",
    "        \n",
    "        if var_str == 'urbanfraction':\n",
    "            files = [file for file in files if '/orig/' not in file]\n",
    "        \n",
    "        int_attr = {'var_name': var_name}\n",
    "        \n",
    "        for file in files:\n",
    "            filename = file.split('/')[-1]\n",
    "            \n",
    "            if '-11' in filename:\n",
    "                lats_ref = np.sort(ds_ref_012.lat.data)\n",
    "                lons_ref = np.sort(ds_ref_012.lon.data)\n",
    "            elif '-22' in filename:\n",
    "                lats_ref = np.sort(ds_ref_025.lat.data)\n",
    "                lons_ref = np.sort(ds_ref_025.lon.data)\n",
    "            \n",
    "            filepath_dest = \"interpolation_results\"\n",
    "            \n",
    "            # Open dataset\n",
    "            ds = xr.open_dataset(file)\n",
    "            \n",
    "            # Select domain and update attributes\n",
    "            lats_ref, lons_ref = select_domain(ds, lats_ref, lons_ref)\n",
    "            int_attr.update({'lats': lats_ref, 'lons': lons_ref, 'interpolation_method': 'conservative_normed'})\n",
    "            \n",
    "            # Interpolation\n",
    "            INTER = Interpolator(int_attr)\n",
    "            ds_inter = INTER(ds)\n",
    "            \n",
    "            # Save results\n",
    "            if not os.path.exists(filepath_dest):\n",
    "                os.makedirs(filepath_dest)\n",
    "            \n",
    "            ds_inter.to_netcdf(f\"{filepath_dest}/{filename}\")\n",
    "            \n",
    "            ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 48.864716 \n",
    "lon = 2.349014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/lustre/gmeteo/WORK/DATA/CORDEX-FPS-URB-RCC/nextcloud/CORDEX-CORE-WG/new/RegCM/sftimf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f\"{root}sftimf_EUR-11c_ICTP_RegCM4-6_v1_fx.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f\"./interpolation_results/sftimf_EUR-11_GERICS_REMO2015_v1_fx.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sel(lon = slice(lon-0.5, lon+0.5 ), lat = slice(lat-0.5, lat+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['sftimf'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dest + '/' +  filename_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in tqdm.tqdm(files):\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    if file.split('/')[-1].split('_')[1].split('-')[1] == '11':\n",
    "        lats_ref = np.sort(ds_ref_012.lat.data)\n",
    "        lons_ref = np.sort(ds_ref_012.lon.data)\n",
    "    elif file.split('/')[-1].split('_')[1].split('-')[1] == '22':\n",
    "        lats_ref = np.sort(ds_ref_025.lat.data)\n",
    "        lons_ref = np.sort(ds_ref_025.lon.data)\n",
    "         \n",
    "    filepath_root = '/'.join(file.split('/')[:-1])\n",
    "    filename_root = file.split('/')[-1]\n",
    "        \n",
    "    # open file\n",
    "    ds = xr.open_dataset(file)\n",
    "    # cut destination grid and update attr\n",
    "    lats_ref, lons_ref = select_domain(ds, lats_ref, lons_ref)\n",
    "    int_attr['lats'] = lats_ref\n",
    "    int_attr['lons'] = lons_ref\n",
    "    \n",
    "    # Conservative\n",
    "    int_attr['interpolation_method'] = 'conservative_normed'\n",
    "    filepath_dest = filepath_root.replace('land-sea-mask', 'land-sea-mask_C')\n",
    "    filename_dest = file.split('/')[-1]\n",
    "\n",
    "    INTER = Interpolator(int_attr)\n",
    "    ds_inter = INTER(ds)\n",
    "    # save the results\n",
    "    if not os.path.exists(filepath_dest):\n",
    "        os.makedirs(filepath_dest)\n",
    "    mask = np.isnan(ds_inter[int_attr['var_name']])\n",
    "    ds_inter.to_netcdf(filepath_dest + '/' +  filename_dest)\n",
    "\n",
    "    # NN\n",
    "    int_attr['interpolation_method'] = 'nearest_s2d'\n",
    "    filepath_dest = filepath_root.replace('land-sea-mask', 'land-sea-mask_N')\n",
    "    filename_dest = file.split('/')[-1]\n",
    "\n",
    "    INTER = Interpolator(int_attr)\n",
    "    ds_inter = INTER(ds)\n",
    "    # save the results\n",
    "    if not os.path.exists(filepath_dest):\n",
    "        os.makedirs(filepath_dest) \n",
    "    ds_inter[int_attr['var_name']] = ds_inter[int_attr['var_name']].where(~mask)\n",
    "    ds_inter.to_netcdf(filepath_dest + '/' +  filename_dest)\n",
    "        \n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dict = {\n",
    "    \"dims\": {\n",
    "        \"bnds\": 2,\n",
    "        \"lon\": len(ds.lon),\n",
    "        \"lat\": len(ds.lat),\n",
    "        #\"time\": len(ds.time),\n",
    "    },\n",
    "    \"coords\": {\n",
    "        \"lon\": {\n",
    "            \"dims\": (\"lon\",),\n",
    "            \"attrs\": {\n",
    "                \"units\": \"degrees_east\",\n",
    "                \"standard_name\": \"longitude\",\n",
    "                \"long_name\": \"longitude\",\n",
    "                \"axis\": \"X\",\n",
    "                \"bounds\": \"lon_bnds\",\n",
    "            },\n",
    "            \"data\": None,\n",
    "        },\n",
    "        \"lat\": {\n",
    "            \"dims\": (\"lat\",),\n",
    "            \"attrs\": {\n",
    "                \"units\": \"degrees_north\",\n",
    "                \"standard_name\": \"latitude\",\n",
    "                \"long_name\": \"latitude\",\n",
    "                \"axis\": \"Y\",\n",
    "                \"bounds\": \"lat_bnds\",\n",
    "            },\n",
    "            \"data\": None,\n",
    "        },\n",
    "        #\"time\": {\"dims\": (\"time\",), \"attrs\": ds.time.attrs, \"data\": ds.time.data},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time:\n",
    "    xr_dict['dims'].update({\"time\":3})\n",
    "    xr_dict['coords'].update({\"dims\": (\"time\",), \"attrs\": ds.time.attrs, \"data\": ds.time.data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_keys_nested_dict(d, keys):\n",
    "    for key in keys:\n",
    "        if key not in d:\n",
    "            d[key] = {}\n",
    "        d = d[key]\n",
    "    d.setdefault(keys[-1], 1)\n",
    " \n",
    " \n",
    "# initializing dictionary\n",
    "test_dict = {'GFG': {'rate': 4, 'since': 2012}}\n",
    " \n",
    "# printing original dictionary\n",
    "print(\"The original dictionary is: \" + str(test_dict))\n",
    " \n",
    "# Add keys to nested dictionary using for loop\n",
    "add_keys_nested_dict(test_dict, ['GFG', 'rank'])\n",
    " \n",
    "# printing result\n",
    "print(\"Dictionary after nested key update: \" + str(test_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rot = xr.open_dataset(file)\n",
    "ds_interp = xr.open_dataset(filepath_dest + '/' +  filename_dest)\n",
    "ds_rot['tasmin'].isel(time = 0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_interp['tasmin'].isel(time = 0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/lustre/gmeteo/WORK/chantreuxa/BA_IPCC/final_products/climate_index/CMIP6/mrsos/gr100/IPSL/IPSL-CM6A-LR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.sort(list(traverseDir(root, '.nc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sces = np.sort(np.unique([f.split('/')[-3] for f in files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n_sce, sce in enumerate(sces):\n",
    "    print(sce)\n",
    "    files_sce = [file for file in files if sce in file]\n",
    "    ds = xr.open_mfdataset(files_sce, \n",
    "                           concat_dim='time',\n",
    "                           combine='nested',\n",
    "                           chunks={'time': 1000})\n",
    "    # delete dates with all nan\n",
    "    ds_mean_time = ds.mean(dim = ('lon', 'lat'), skipna=True)\n",
    "    no_null = ~pd.isnull(ds_mean_time['mrsos'].values)\n",
    "    ds = ds.isel(time = no_null)\n",
    "    if n_sce == 0:\n",
    "        ds_mean = ds.mean(dim = ('time'), skipna=False)\n",
    "    else:\n",
    "        ds_aux = ds.mean(dim = ('time'), skipna=False)\n",
    "        ds_mean['mrsos'][:] = ds_mean['mrsos'].values + ds_aux['mrsos'].values\n",
    "\n",
    "ds_mean['mrsos'][:] = ds_mean['mrsos'].values/len(sces)\n",
    "\n",
    "ds_mean[\"mask\"]=(['lat', 'lon'],  xr.where(~pd.isnull(ds_mean['mrsos']), 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean[\"mask\"].attrs[\"commet\"] = \"Mask calculated using all files and scenarios for this simulation. A value of 1 indicates cells with no NaNs in any file (across time and scenarios), while a value of 0 indicates the opposite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean.to_netcdf('mrsos_gr100_mon_CMIP6_IPSL_IPSL-CM6A-LR_r1i1p1f1_mon.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/lustre/gmeteo/WORK/PROYECTOS/2020_C3S_34d/CORDEX_PROVIDERS/CORDEX_NAM_UCAR/DATA/canrcm4/canesm2/nam-22/hist/day/tas_NAM-22_CCCma-CanESM2_historical_r1i1p1_CCCma-CanRCM4_r2_day_20010101-20051231.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['tas'].isel(time = 0).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
